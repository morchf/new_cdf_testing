{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPS data is normally sent to the CreateRTRADIOMsg lambda in AirLink Telemetry Protocol (ATP)\n",
    "\n",
    "For this solution, it will be filled in with data from GTFS Realtime feeds, with estimated values compensating for the slower message rate\n",
    "\n",
    "This notebook will show how to get that and test agencies to ensure they have fully provided the GPS data in their feed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPSData:\n",
    "    def __init__(\n",
    "        self, latitude, longitude, bearing, speed, timestamp=None, vehicle_id=None\n",
    "    ):\n",
    "        if vehicle_id:\n",
    "            self.vehicle_id = vehicle_id\n",
    "        if timestamp:\n",
    "            self.timestamp = datetime.fromtimestamp(timestamp)\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.bearing = bearing\n",
    "        self.speed = speed\n",
    "\n",
    "    def __repr__(self):\n",
    "        type_name = type(self).__name__\n",
    "        attr_string = \", \".join([f\"{k}={v!r}\" for k, v in vars(self).items()])\n",
    "        return f\"{type_name}({attr_string})\"\n",
    "\n",
    "    def __str__(self):\n",
    "        type_name = type(self).__name__\n",
    "        max_attr_len = len(max(vars(self), key=len))\n",
    "        attr_strings = [f\"{k:{max_attr_len}}  {v}\" for k, v in vars(self).items()]\n",
    "        return \"\\n  \".join([type_name] + attr_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poll the vehicle position the GTFS Realtime VehiclePosition feed directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsp_gtfs_realtime.core.gtfs_realtime import GTFSRealtimeAPIPoller, GTFSRealtimeConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point `config_folder` to a folder with agency json config files, or set `config_files` manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all config files\n",
    "config_folder = Path(\"../tsp_gtfs_realtime/config/agencies\")\n",
    "config_files = sorted(config_folder.glob(\"*.json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poll each feed `num_samples` times\n",
    "\n",
    "Instantiating the pollers outside the loop allows them each to manage the polling rate. This could be parallelized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pollers for each feed\n",
    "agency_gtfs_realtime_api_poller = {\n",
    "    config_file.stem: GTFSRealtimeAPIPoller(GTFSRealtimeConfig.from_inputs(config_file=config_file)) for config_file in config_files\n",
    "}\n",
    "agency_gps_data = {config_file.stem: [] for config_file in config_files}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "\n",
    "for sample_idx in range(num_samples):\n",
    "    for agency, gtfs_realtime_api_poller in agency_gtfs_realtime_api_poller.items():\n",
    "        print(f\"Sample {sample_idx}, Polling {agency}\")\n",
    "        try:\n",
    "            gtfs_realtime_api_poller.poll_vehicle_positions()\n",
    "            agency_gps_data[agency].extend(\n",
    "                [\n",
    "                    GPSData(\n",
    "                        vehicle_id=fields.get(\"vehicle_id\"),\n",
    "                        timestamp=fields.get(\"timestamp\"),\n",
    "                        latitude=fields.get(\"latitude\"),\n",
    "                        longitude=fields.get(\"longitude\"),\n",
    "                        bearing=fields.get(\"bearing\"),\n",
    "                        speed=fields.get(\"speed\"),\n",
    "                    )\n",
    "                    for _, fields in gtfs_realtime_api_poller.vehicle_positions\n",
    "                ]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Error, skipping {agency} {sample_idx}\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case some agency never got good data delete it\n",
    "for agency in list(agency_gps_data):\n",
    "    if not agency_gps_data[agency]:\n",
    "        print(f\"{agency} never received good data, deleting\")\n",
    "        del agency_gtfs_realtime_api_poller[agency]\n",
    "        del agency_gps_data[agency]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this probably should just replace agency_gps_data entirely\n",
    "# create dataframe for each agency\n",
    "df_agency_gps_data = {\n",
    "    agency: pd.DataFrame([vars(d) for d in gps_data])\n",
    "    for agency, gps_data in agency_gps_data.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can also be saved to a csv file for further investigation or just appending data from different polling times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_save_csv = True\n",
    "should_append = True\n",
    "\n",
    "csv_folder = Path(\"./output/csv/\")\n",
    "csv_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if should_save_csv:\n",
    "    for agency, df_gps_data in df_agency_gps_data.items():\n",
    "        csv_file = csv_folder.joinpath(f\"{agency}.csv\")\n",
    "        if should_append and csv_file.is_file():\n",
    "            df_gps_data = pd.concat(\n",
    "                [pd.read_csv(csv_file), df_gps_data], ignore_index=True\n",
    "            ).drop_duplicates()\n",
    "        df_gps_data.to_csv(csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a markdown summary of the agencies\n",
    "\n",
    "This notes if any fields are missing, splitting these agencies to another section\n",
    "\n",
    "It also notes the location with a link to the developer resources provided by the agency, and makes a table from a sample excerpt of the data\n",
    "\n",
    "This is mainly to make copying to confluence easy, which can either be pasted directly, or require right-click > \"Paste and Match Style\" while editing a document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the data, determine which agencies fully populate the gps data, save summary to markdown file\n",
    "md_file = csv_folder.joinpath(\"summary.md\")\n",
    "missing_md_lines = []\n",
    "populated_md_lines = []\n",
    "\n",
    "for agency, df_gps_data in df_agency_gps_data.items():\n",
    "    agency_name = agency.title().replace(\"_\", \" \")\n",
    "    # get agency feed documentation link\n",
    "    with open(config_folder.joinpath(f\"{agency}.json\")) as fp:\n",
    "        data = json.load(fp)\n",
    "        documentation_url = data.get(\"developer_resources\")\n",
    "        location = data.get(\"location\")\n",
    "        location_url_md = f\"[{location}]({documentation_url})\"\n",
    "\n",
    "    missing_fields = (\n",
    "        df_gps_data[[\"latitude\", \"longitude\", \"bearing\", \"speed\"]] == 0\n",
    "    ).all()\n",
    "    if missing_fields.any():\n",
    "        # bold missing fields\n",
    "        missing_fields_str = \", \".join(\n",
    "            [f\"**{a}**\" for a in missing_fields[missing_fields].index]\n",
    "        )\n",
    "        missing_md_lines += [\n",
    "            f\"### {agency_name}\",\n",
    "            location_url_md,\n",
    "            \"\",\n",
    "            f\"Missing {missing_fields_str}\",\n",
    "            df_gps_data.head(10).to_markdown(index=False),\n",
    "            \"\",\n",
    "        ]\n",
    "    else:\n",
    "        populated_md_lines += [\n",
    "            f\"### {agency_name}\",\n",
    "            location_url_md,\n",
    "            # print sample from fully populated rows\n",
    "            df_gps_data.loc[(df_gps_data != 0).all(axis=1)]\n",
    "            .head(10)\n",
    "            .to_markdown(index=False),\n",
    "            \"\",\n",
    "        ]\n",
    "\n",
    "with open(md_file, \"w\") as fp:\n",
    "    print(f\"## Agencies with Missing gps_data Fields\", file=fp)\n",
    "    print(*missing_md_lines, sep=\"\\n\", file=fp)\n",
    "    print(f\"## Agencies with Fully Populated gps_data\", file=fp)\n",
    "    print(*populated_md_lines, sep=\"\\n\", file=fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the execution here when selecting \"Run All\", while not closing the kernel,\n",
    "# still allowing the below cells to be run manually\n",
    "raise SystemExit(\"Done, the following cells can be executed manually\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "Alternatively, you could get the data from redis, with the api poller putting it there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsp_gtfs_realtime import AWSConfig\n",
    "from tsp_gtfs_realtime.vehicle_manager import VehicleSubscriber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create video subscriber and subscribe to all vehicle updates\n",
    "aws_cfg = AWSConfig(\n",
    "    local_development=True,\n",
    "    redis_url=\"localhost\",\n",
    "    redis_port=6379,\n",
    ")\n",
    "vehicle_subscriber = VehicleSubscriber(aws_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first message is the subscription notification\n",
    "msg = vehicle_subscriber.pubsub.get_message()\n",
    "\n",
    "# get new vehicle_position message and vehicle_id\n",
    "msg = vehicle_subscriber.pubsub.get_message()\n",
    "vehicle_id = msg[\"channel\"].split(\":\")[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new vehicle_position data from cache\n",
    "vehicle_subscriber.get_updated_vehicle_position(vehicle_id)\n",
    "\n",
    "# get fields for gps_data AirLink Telemetry Protocol (ATP)\n",
    "gps_data = GPSData(\n",
    "    vehicle_id=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"vehicle_id\"),\n",
    "    timestamp=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"timestamp\"),\n",
    "    latitude=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"latitude\"),\n",
    "    longitude=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"longitude\"),\n",
    "    bearing=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"bearing\"),\n",
    "    speed=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"speed\"),\n",
    ")\n",
    "\n",
    "print(f\"{vehicle_id}: {gps_data!r}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
