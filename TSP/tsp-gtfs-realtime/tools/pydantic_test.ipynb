{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic\n",
    "playing with pydantic model and settings features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "gps_json = '{\"latitude\": 34.7276107, \"longitude\": -122.0421016220921, \"speed\": 0.0, \"heading\": 2.0}'\n",
    "\n",
    "gps_dict = json.loads(gps_json)\n",
    "gps_list = list(gps_dict.values())\n",
    "\n",
    "gps_latitude = gps_dict[\"latitude\"]\n",
    "gps_longitude = gps_dict[\"longitude\"]\n",
    "gps_speed = gps_dict[\"speed\"]\n",
    "gps_heading = gps_dict[\"heading\"]\n",
    "\n",
    "print(gps_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataclass\n",
    "Pydantic provides a drop-in replacement for standard python dataclasses with additional validation functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "@pydantic.dataclasses.dataclass\n",
    "class GPSData_pydantic_dataclass:\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    speed: float\n",
    "    heading: float\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class GPSData_standard_dataclass:\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    speed: float\n",
    "    heading: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid ways of instantiating\n",
    "# keyword\n",
    "gps_pydantic_dataclass = GPSData_pydantic_dataclass(\n",
    "    latitude=gps_latitude,\n",
    "    longitude=gps_longitude,\n",
    "    speed=gps_speed,\n",
    "    heading=gps_heading,\n",
    ")\n",
    "# positional\n",
    "gps_pydantic_dataclass1 = GPSData_pydantic_dataclass(gps_latitude, gps_longitude, gps_speed, gps_heading)\n",
    "# keyword by unpacking dict\n",
    "gps_pydantic_dataclass2 = GPSData_pydantic_dataclass(**gps_dict)\n",
    "# positional by unpacking list/tuple\n",
    "gps_pydantic_dataclass3 = GPSData_pydantic_dataclass(*gps_list)\n",
    "\n",
    "# all create equivalent objects\n",
    "assert gps_pydantic_dataclass == gps_pydantic_dataclass1 == gps_pydantic_dataclass2 == gps_pydantic_dataclass3\n",
    "\n",
    "# same functionality as standard dataclass\n",
    "# keyword\n",
    "gps_standard_dataclass = GPSData_standard_dataclass(\n",
    "    latitude=gps_latitude,\n",
    "    longitude=gps_longitude,\n",
    "    speed=gps_speed,\n",
    "    heading=gps_heading,\n",
    ")\n",
    "# positional\n",
    "gps_standard_dataclass1 = GPSData_standard_dataclass(gps_latitude, gps_longitude, gps_speed, gps_heading)\n",
    "# keyword by unpacking dict\n",
    "gps_standard_dataclass2 = GPSData_standard_dataclass(**gps_dict)\n",
    "# positional by unpacking list/tuple\n",
    "gps_standard_dataclass3 = GPSData_standard_dataclass(*gps_list)\n",
    "\n",
    "# all create equivalent objects\n",
    "assert gps_standard_dataclass == gps_standard_dataclass1 == gps_standard_dataclass2 == gps_standard_dataclass3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these dataclasses cannot be compared to each other, because the pydantic dataclass adds additional attributes that leads to a different `__dict__` attribute (which can be gotten with `vars()`). They would need to explicitly compared by looking at `__dict__` from the standard dataclass since it should be a subset, using the hidden attribute `__dataclass_fields__`, or using standard `dataclasses.asdict()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    vars(gps_pydantic_dataclass),\n",
    "    vars(gps_standard_dataclass),\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(gps_pydantic_dataclass == gps_standard_dataclass)=}\")\n",
    "# get values directly by referencing __dataclass_fields__ attribute\n",
    "assert (\n",
    "    all(\n",
    "        getattr(gps_pydantic_dataclass, k) == getattr(gps_standard_dataclass, k)\n",
    "        for k in vars(gps_standard_dataclass)\n",
    "        # for k in gps_pydantic_dataclass.__dataclass_fields__\n",
    "    )\n",
    ")\n",
    "print(f\"{(dataclasses.asdict(gps_pydantic_dataclass) == dataclasses.asdict(gps_standard_dataclass))=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str/repr\n",
    "print(\n",
    "    \"GPSData_pydantic_dataclass:\",\n",
    "    f\"  str:  {gps_pydantic_dataclass}\",\n",
    "    f\"  repr: {gps_pydantic_dataclass!r}\",\n",
    "    \"GPSData_standard_dataclass:\",\n",
    "    f\"  str:  {gps_standard_dataclass}\",\n",
    "    f\"  repr: {gps_standard_dataclass!r}\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "# instance methods\n",
    "print(\n",
    "    \"GPSData_pydantic_dataclass:\",\n",
    "    *[\n",
    "        f\"{field}: {value}\"\n",
    "        for field, value in inspect.getmembers(gps_pydantic_dataclass)\n",
    "        if not field.startswith(\"_\")\n",
    "    ],\n",
    "    sep=\"\\n  \",\n",
    ")\n",
    "print(\n",
    "    \"GPSData_standard_dataclass:\",\n",
    "    *[\n",
    "        f\"{field}: {value}\"\n",
    "        for field, value in inspect.getmembers(gps_standard_dataclass)\n",
    "        if not field.startswith(\"_\")\n",
    "    ],\n",
    "    sep=\"\\n  \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation just checks that the input data can be coerced to the expected type\n",
    "gps_latitude_str = str(gps_latitude)\n",
    "gps_longitude_padded_str = f\"{gps_longitude}    \"\n",
    "gps_speed_invalid_str = \"some string\"\n",
    "\n",
    "# invalid speed input\n",
    "try:\n",
    "    print(\n",
    "        GPSData_pydantic_dataclass(\n",
    "            latitude=gps_latitude_str,\n",
    "            longitude=gps_longitude_padded_str,\n",
    "            speed=gps_speed_invalid_str,\n",
    "            heading=0,\n",
    "        )\n",
    "    )\n",
    "except pydantic.ValidationError as e:\n",
    "    print(e)\n",
    "\n",
    "# valid, coercible inputs\n",
    "try:\n",
    "    print(\n",
    "        GPSData_pydantic_dataclass(\n",
    "            latitude=gps_latitude_str,\n",
    "            longitude=gps_longitude_padded_str,\n",
    "            speed=gps_speed,\n",
    "            heading=0,\n",
    "        )\n",
    "    )\n",
    "except pydantic.ValidationError as e:\n",
    "    print(e)\n",
    "\n",
    "# but with standard dataclasses, the values are not checked or coerced\n",
    "print(\n",
    "    GPSData_standard_dataclass(\n",
    "        latitude=gps_latitude_str,\n",
    "        longitude=gps_longitude_padded_str,\n",
    "        speed=gps_speed_invalid_str,\n",
    "        heading=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseModel\n",
    "Similar to dataclasses, with additional functionality like (de)serializing from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPSData_pydantic_base_model(pydantic.BaseModel):\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    speed: float\n",
    "    heading: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when instantiating, positional arguments are not allowed so keywords must be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid ways of instantiating\n",
    "# keyword\n",
    "gps_pydantic_base_model = GPSData_pydantic_base_model(\n",
    "    latitude=gps_latitude,\n",
    "    longitude=gps_longitude,\n",
    "    speed=gps_speed,\n",
    "    heading=gps_heading,\n",
    ")\n",
    "# unpacking dict\n",
    "gps_pydantic_base_model1 = GPSData_pydantic_base_model(**gps_dict)\n",
    "# from dict using parse_obj\n",
    "gps_pydantic_base_model2 = GPSData_pydantic_base_model.parse_obj(gps_dict)\n",
    "# from json using parse_raw\n",
    "gps_pydantic_base_model3 = GPSData_pydantic_base_model.parse_raw(gps_json)\n",
    "# a json file could also potentially be used\n",
    "# gps_pydantic_base_model = GPSData_pydantic_base_model.parse_file(gps_file.json)\n",
    "# construct can be used to bypass validation\n",
    "gps_pydantic_base_model4 = GPSData_pydantic_base_model.construct(**gps_dict)\n",
    "# from an existing object using deep/shallow copy\n",
    "gps_pydantic_base_model5 = GPSData_pydantic_base_model.copy(gps_pydantic_base_model)\n",
    "gps_pydantic_base_model6 = GPSData_pydantic_base_model.copy(gps_pydantic_base_model, deep=True)\n",
    "\n",
    "# all create equivalent objects\n",
    "assert gps_pydantic_base_model == gps_pydantic_base_model1 == gps_pydantic_base_model2 == gps_pydantic_base_model3 == gps_pydantic_base_model4 == gps_pydantic_base_model5 == gps_pydantic_base_model6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str/repr, dict, json\n",
    "print(\n",
    "    \"GPSData_pydantic_base_model:\",\n",
    "    f\"str:  {gps_pydantic_base_model}\",\n",
    "    f\"repr: {gps_pydantic_base_model!r}\",\n",
    "    f\"dict: {gps_pydantic_base_model.dict()!r}\",\n",
    "    f\"json: {gps_pydantic_base_model.json()!r}\",\n",
    "    sep=\"\\n  \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "# instance/class methods\n",
    "print(\n",
    "    \"GPSData_pydantic_base_model:\",\n",
    "    *[\n",
    "        f\"{field}: {value}\"\n",
    "        for field, value in inspect.getmembers(gps_pydantic_base_model)\n",
    "        if not field.startswith(\"_\")\n",
    "    ],\n",
    "    sep=\"\\n  \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and constraints\n",
    "Validating values beyond type checking can be configured using [helper constrained types](https://pydantic-docs.helpmanual.io/usage/types/#constrained-types), the [`Field` class](https://pydantic-docs.helpmanual.io/usage/schema/#field-customization), or custom [validation functions](https://pydantic-docs.helpmanual.io/usage/validators/).\n",
    "\n",
    "Note that constrained types can be used in conjunction with `Field`, but constraints specified using `Field` [will not be enforced](https://pydantic-docs.helpmanual.io/usage/schema/#unenforced-field-constraints) and an Exception is thrown if attempted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPSData_helpers(pydantic.BaseModel):\n",
    "    latitude: pydantic.confloat(ge=-90, le=90)\n",
    "    longitude: pydantic.confloat(ge=-180, le=180)\n",
    "    speed: pydantic.NonNegativeFloat\n",
    "    heading: pydantic.confloat(ge=0, le=360)\n",
    "\n",
    "class GPSData_fields(pydantic.BaseModel):\n",
    "    latitude: float | None = pydantic.Field(ge=-90, le=90, default=None)\n",
    "    longitude: float = pydantic.Field(ge=-180, le=180)\n",
    "    speed: float = pydantic.Field(ge=0)\n",
    "    heading: float = pydantic.Field(ge=0, le=360)\n",
    "    class Config:\n",
    "        validate_assignment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_latitude_str = str(gps_latitude)\n",
    "gps_longitude_padded_str = f\"{gps_longitude}    \"\n",
    "gps_longitude_padded_out_str = f\"{gps_longitude + 370}    \"\n",
    "gps_speed_invalid_str = \"some string\"\n",
    "\n",
    "gps_data_invalid_speed = {\n",
    "    \"latitude\": gps_latitude_str,\n",
    "    \"longitude\": gps_longitude_padded_str,\n",
    "    \"speed\": gps_speed_invalid_str,\n",
    "    \"heading\": 0,\n",
    "}\n",
    "gps_data_in_constraint = {\n",
    "    \"latitude\": gps_latitude_str,\n",
    "    \"longitude\": gps_longitude_padded_str,\n",
    "    \"speed\": gps_speed,\n",
    "    \"heading\": 0,\n",
    "}\n",
    "gps_data_out_constraint = {\n",
    "    \"latitude\": gps_latitude + 100,\n",
    "    \"longitude\": gps_longitude_padded_out_str,\n",
    "    \"speed\": gps_speed - 10,\n",
    "    \"heading\": -10,\n",
    "}\n",
    "\n",
    "# invalid speed input\n",
    "try:\n",
    "    print(GPSData_pydantic_base_model.parse_obj(gps_data_invalid_speed))\n",
    "except pydantic.ValidationError as e:\n",
    "    print(e)\n",
    "\n",
    "# valid, coercible inputs\n",
    "print(\n",
    "    GPSData_pydantic_base_model.parse_obj(gps_data_in_constraint),\n",
    "    GPSData_helpers.parse_obj(gps_data_in_constraint),\n",
    "    GPSData_fields.parse_obj(gps_data_in_constraint),\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n",
    "# coercible, but not within constraints\n",
    "print(GPSData_pydantic_base_model.parse_obj(gps_data_out_constraint))\n",
    "try:\n",
    "    print(GPSData_helpers.parse_obj(gps_data_out_constraint))\n",
    "except pydantic.ValidationError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    print(GPSData_fields.parse_obj(gps_data_out_constraint))\n",
    "except pydantic.ValidationError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom validation can be done on the model-level or individual attributes. Some things to note:\n",
    "- all these validation methods can be done with pydantic dataclasses\n",
    "- the value passed to the validator has already been coerced to the correct type unless `@validator` is used with `pre=True`. There is not type checking on the value returned from the validator\n",
    "- if an [attribute's validity depends on another attribute](https://pydantic-docs.helpmanual.io/usage/models/#field-ordering), the dependent attribute should be defined after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPSData_custom_validators(pydantic.BaseModel):\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    speed: float\n",
    "    heading: float\n",
    "\n",
    "    @pydantic.validator(\"latitude\")\n",
    "    def clamp_latitude(cls, latitude):\n",
    "        # if value is outside [-90, 90], just clamp to be within limits\n",
    "        return max(-90.0, min(latitude, 90.0))\n",
    "\n",
    "    # @pydantic.validator(\"longitude\", pre=True)\n",
    "    # def wrap_longitude(cls, longitude):\n",
    "    #     # if value is outside [-180, 180], wrap around\n",
    "    #     return ((longitude + 180) % 360) - 180\n",
    "    \n",
    "    @pydantic.validator(\"longitude\")\n",
    "    def wrap_longitude(cls, longitude):\n",
    "        # if value is outside [-180, 180], wrap around\n",
    "        return ((longitude + 180) % 360) - 180\n",
    "    \n",
    "    # @pydantic.validator(\"speed\")\n",
    "    # def validate_speed(cls, speed):\n",
    "    #     # just raise an error instead of fixing\n",
    "    #     if not speed >= 0:\n",
    "    #         raise ValueError(\"speed should be non-negative\")\n",
    "    #     return speed\n",
    "\n",
    "    @pydantic.validator(\"speed\")\n",
    "    def clamp_speed(cls, speed):\n",
    "        # if negative, clamp to 0\n",
    "        return max(speed, 0.0)\n",
    "\n",
    "    @pydantic.validator(\"heading\")\n",
    "    def wrap_heading(cls, heading):\n",
    "        # wrap around to be between [0, 360)\n",
    "        return heading % 360\n",
    "\n",
    "class GPSData_custom_root_validators(pydantic.BaseModel):\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    speed: float\n",
    "    heading: float\n",
    "\n",
    "    @pydantic.root_validator\n",
    "    def clamp_values(cls, values):\n",
    "        values[\"latitude\"] = max(-90.0, min(values[\"latitude\"], 90.0))\n",
    "        return values\n",
    "\n",
    "    @pydantic.root_validator\n",
    "    def handle_negative_speed(cls, values):\n",
    "        if values[\"speed\"] < 0:\n",
    "            values[\"speed\"] *= -1\n",
    "            values[\"heading\"] += 180\n",
    "        return values\n",
    "\n",
    "    @pydantic.root_validator\n",
    "    def wrap_values(cls, values):\n",
    "        values[\"longitude\"] = ((values[\"longitude\"] + 180) % 360) - 180\n",
    "        values[\"heading\"] = values[\"heading\"] % 360\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    GPSData_pydantic_base_model.parse_obj(gps_data_out_constraint),\n",
    "    GPSData_custom_validators.parse_obj(gps_data_out_constraint),\n",
    "    GPSData_custom_root_validators.parse_obj(gps_data_out_constraint),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseSettings\n",
    "The BaseSettings class works similarly to BaseModel but when instantiating, but it tries to get any missing values using case insensitive environment variables, and variables in a `.env` or secrets file.\n",
    "\n",
    "It also supports custom sources that we could create to query the asset library, for example. So for something like the agency_id it might look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo: investigate BaseSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseSettings\n",
    "\n",
    "def query_cdf(settings: BaseSettings):\n",
    "  if should_query_cdf:\n",
    "    response = response_from_asset_library()\n",
    "    return response.json()\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "  agency_id: str = \"no_agency\"\n",
    "  class Config:\n",
    "      @classmethod\n",
    "      def customise_sources(cls, init, env, file):\n",
    "        return (init, env, query_cdf, file)\n",
    "\n",
    "# parser = ArgumentParser()\n",
    "# parser.add_argument(\"--agency-id\")\n",
    "# arg_dict = vars(parser.parse_args())\n",
    "arg_dict = {\"agency_id\": \"example_agency_id\"}\n",
    "\n",
    "config = Settings(_env_file=\".env\", **arg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import os\n",
    "from pydantic import BaseModel, root_validator, validator, PositiveFloat, validate_arguments, HttpUrl, FilePath\n",
    "from pydantic.typing import Literal, Optional\n",
    "\n",
    "class GTFSRealtimeConfig_pydantic(BaseModel):\n",
    "    vehicle_positions_url: Optional[str]\n",
    "    trip_updates_url: Optional[str]\n",
    "    alerts_url: Optional[str]\n",
    "    vehicle_id_field: Literal[\"id\", \"label\"] = \"id\"\n",
    "    max_polling_rate: PositiveFloat = 15\n",
    "    subscribed_till: Optional[date]\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def get_gtfs_realtime_api_from_features(cls, values):\n",
    "        if \"Features\" in values:\n",
    "            values = values[\"Features\"]\n",
    "        if \"gtfs-realtime\" in values:\n",
    "            values = values[\"gtfs-realtime\"]\n",
    "        return values\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def disregard_empty_values(cls, values):\n",
    "        return {k: v for k, v in values.items() if v}\n",
    "\n",
    "    @root_validator()\n",
    "    def ensure_at_least_one_url(cls, values):\n",
    "        if not any(\n",
    "            values.get(key)\n",
    "            for key in (\"vehicle_positions_url\", \"trip_updates_url\", \"alerts_url\")\n",
    "        ):\n",
    "            raise ValueError(\"At least one api endpoint is required\")\n",
    "        return values\n",
    "\n",
    "    @classmethod\n",
    "    @validate_arguments\n",
    "    def from_inputs(\n",
    "        cls,\n",
    "        feature_persistence_url: HttpUrl = None,\n",
    "        agency_id: str = None,\n",
    "        should_query_feature_api: bool = False,\n",
    "        config_file: FilePath = None,\n",
    "    ):\n",
    "        # default config file location\n",
    "        config_dir = os.path.join(os.path.dirname(os.getcwd()), \"tsp_gtfs_realtime\", \"config\")\n",
    "        default_config_file = os.path.join(config_dir, \"gtfs-realtime-api-poller.json\")\n",
    "\n",
    "        # query feature persistence api\n",
    "        if should_query_feature_api:\n",
    "            if config_file:\n",
    "                print(\n",
    "                    f\"config_file provided, but {should_query_feature_api=}, disregarding config_file\"\n",
    "                )\n",
    "            if not (feature_persistence_url and agency_id):\n",
    "                raise ValueError(\n",
    "                    \"feature_persistence_url and agency_id are required to query feature api\"\n",
    "                )\n",
    "            url = f\"{feature_persistence_url}/FeaturePersistence?AgencyGUID={agency_id}\"\n",
    "            response = requests.get(url)\n",
    "            return GTFSRealtimeConfig_pydantic.parse_raw(response.content)\n",
    "        # else create from config_file\n",
    "        return GTFSRealtimeConfig_pydantic.parse_file(\n",
    "            config_file or default_config_file\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_json = '{\"gtfs-realtime\": {\"vehicle_positions_url\":\"http://uctransit.info/gtfs-rt/vehiclepositions\",\"trip_updates_url\":\"http://uctransit.info/gtfs-rt/tripupdates\",\"alerts_url\":\"http://uctransit.info/gtfs-rt/alerts\",\"vehicle_id_field\":\"label\",\"max_polling_rate\":\"\",\"subscribed_till\":\"\"}}'\n",
    "feature_dict = {\n",
    "    \"gtfs-realtime\": {\n",
    "        \"vehicle_positions_url\": \"http://uctransit.info/gtfs-rt/vehiclepositions\",\n",
    "        \"trip_updates_url\": \"http://uctransit.info/gtfs-rt/tripupdates\",\n",
    "        \"alerts_url\": \"http://uctransit.info/gtfs-rt/alerts\",\n",
    "        \"vehicle_id_field\": \"label\",\n",
    "        \"max_polling_rate\": \"\",\n",
    "        \"subscribed_till\": \"\",\n",
    "    }\n",
    "}\n",
    "feature = feature_dict.get(\"gtfs-realtime\")\n",
    "\n",
    "GTFSRealtimeConfig_pydantic.parse_obj(\n",
    "    {\n",
    "        \"gtfs-realtime\": {\n",
    "            \"vehicle_positions_url\": \"asdfasdf\",\n",
    "            \"trip_updates_url\": \"\",\n",
    "            \"alerts_url\": \"\",\n",
    "            \"vehicle_id_field\": \"label\",\n",
    "            \"max_polling_rate\": \"\",\n",
    "            \"subscribed_till\": \"\",\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFSRealtimeConfig_pydantic.parse_file(\"../config/gtfs-realtime-api-poller.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "feature_persistence_url = \"https://2g4ct7tedk.execute-api.us-east-1.amazonaws.com/default\"\n",
    "agency_id = \"unioncity\"\n",
    "\n",
    "response = requests.get(f\"{feature_persistence_url}/FeaturePersistence?AgencyGUID={agency_id}\")\n",
    "GTFSRealtimeConfig_pydantic.parse_raw(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_persistence_url = \"https://2g4ct7tedk.execute-api.us-east-1.amazonaws.com/default\"\n",
    "agency_id = \"unioncity\"\n",
    "\n",
    "cfg_from_api = GTFSRealtimeConfig_pydantic.from_inputs(\n",
    "    feature_persistence_url=feature_persistence_url,\n",
    "    agency_id=agency_id,\n",
    "    should_query_feature_api=True,\n",
    ")\n",
    "\n",
    "cfg_from_file = GTFSRealtimeConfig_pydantic.from_inputs(\n",
    "    config_file=\"../tsp_gtfs_realtime/config/gtfs-realtime-api-poller.json\"\n",
    ")\n",
    "\n",
    "cfg_from_default_file = GTFSRealtimeConfig_pydantic.from_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsp_gtfs_realtime import GTFSRealtimeConfig\n",
    "\n",
    "GTFSRealtimeConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "integration_com_raw = \"\"\"{\"attributes\":{\"gttSerial\":\"643\",\"serial\":\"643\",\"addressMAC\":\"00:00:00:d0:06:43\",\"preemptionLicense\":\"pending\",\"integration\":\"gtfs-realtime\",\"uniqueId\":\"643dde30-1de5-47c0-ac61-5580a7232e9f\"},\"groups\":{\"ownedby\":[\"/unioncity/unioncity\"]},\"devices\":{\"installedat\":[\"union-city-vehicle-643\"]},\"category\":\"device\",\"templateId\":\"integrationcom\",\"description\":\"TSP in the Cloud Demo\",\"state\":\"active\",\"deviceId\":\"tsp-gtfs-realtime-643\"}\"\"\"\n",
    "integration_com_dict = json.loads(integration_com_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IntegrationCom\n",
    "\n",
    "template\n",
    "``` yaml\n",
    "templateId: integrationcom\n",
    "category: device\n",
    "properties:\n",
    "  description:\n",
    "    type: [string,null]\n",
    "  serial:\n",
    "    type: string\n",
    "  gttSerial:\n",
    "    type: string\n",
    "  addressMAC:\n",
    "    type: [string,null]\n",
    "  uniqueId:\n",
    "    type: string\n",
    "  preemptionLicense:\n",
    "    type: [string,null]\n",
    "    enum: [pending,inactive,active,decommissioned,transferred]\n",
    "  integration:\n",
    "    type: [string,null]\n",
    "    enum: [Whelen,Teletrac,gtfs-realtime,Misc.]\n",
    "relations:\n",
    "  out:\n",
    "    ownedby: [agency]\n",
    "required:\n",
    "  - uniqueId\n",
    "  - addressMAC\n",
    "  - serial\n",
    "```\n",
    "\n",
    "example response:\n",
    "``` yaml\n",
    "attributes:\n",
    "  gttSerial: '643'\n",
    "  serial: '643'\n",
    "  addressMAC: 00:00:00:d0:06:43\n",
    "  preemptionLicense: pending\n",
    "  integration: gtfs-realtime\n",
    "  uniqueId: 643dde30-1de5-47c0-ac61-5580a7232e9f\n",
    "groups:\n",
    "  ownedby:\n",
    "  - \"/unioncity/unioncity\"\n",
    "devices:\n",
    "  installedat:\n",
    "  - union-city-vehicle-643\n",
    "category: device\n",
    "templateId: integrationcom\n",
    "description: TSP in the Cloud Demo\n",
    "state: active\n",
    "deviceId: tsp-gtfs-realtime-643\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, conint, constr, Field\n",
    "from pydantic.typing import Literal, List\n",
    "\n",
    "class IntegrationComAttributes(BaseModel):\n",
    "    serial: str\n",
    "    gtt_serial: str = Field(alias=\"gttSerial\")\n",
    "    address_mac: constr(regex=r\"^([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$\") = Field(alias=\"addressMAC\")\n",
    "    unique_id: str = Field(alias=\"uniqueId\")\n",
    "    license: Literal[\"pending\", \"inactive\", \"active\", \"decommissioned\", \"transferred\"] = Field(alias=\"preemptionLicense\")\n",
    "    integration: Literal[\"Whelen\", \"Teletrac\", \"gtfs-realtime\", \"Misc.\"]\n",
    "\n",
    "class IntegrationComOwnedBy(BaseModel):\n",
    "    # match \"/region/agency\", where each is alphanumeric with underscores/hyphens\n",
    "    owned_by: List[constr(regex=r\"^\\/[\\w-]+\\/[\\w-]+$\")] = Field(alias=\"ownedby\")\n",
    "\n",
    "class IntegrationComGroups(BaseModel):\n",
    "    # match \"/region/agency\", where each is alphanumeric with underscores/hyphens\n",
    "    dir_out: IntegrationComOwnedBy = Field(alias=\"out\")\n",
    "\n",
    "class IntegrationComInstalledAt(BaseModel):\n",
    "    installed_at: List[str] = Field(alias=\"installedat\")\n",
    "\n",
    "class IntegrationComDevices(BaseModel):\n",
    "    dir_in: IntegrationComInstalledAt = Field(alias=\"in\")\n",
    "\n",
    "class IntegrationCom(BaseModel):\n",
    "    description: str = None\n",
    "    attributes: IntegrationComAttributes\n",
    "    groups: IntegrationComGroups\n",
    "    devices: IntegrationComDevices\n",
    "    category: Literal[\"device\"]\n",
    "    template_id: Literal[\"integrationcom\"] = Field(alias=\"templateId\")\n",
    "    description: str = None\n",
    "    state: Literal[\"active\"]\n",
    "    device_id: str = Field(alias=\"deviceId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = IntegrationCom.parse_raw(integration_com_raw)\n",
    "# device = IntegrationCom.parse_obj(integration_com_dict)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_com_dict\n",
    "# integration_com_dict[\"attributes\"].get(\"addressMAC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.awsrequest import AWSRequest\n",
    "from botocore.endpoint import URLLib3Session\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.compat import urlencode, quote\n",
    "\n",
    "\n",
    "base_url = \"https://oo9fn5p38b.execute-api.us-east-1.amazonaws.com/Prod\"\n",
    "region_name = \"UnionCity\" # not case sensitive\n",
    "agency_name = \"UnionCity\" # not case sensitive\n",
    "device_id = \"tsp-gtfs-realtime-643\"\n",
    "ancestor_path = quote(f\"/{region_name}/{agency_name}\", safe=\"\")\n",
    "print(f\"{ancestor_path=}\")\n",
    "\n",
    "template_type_dict = {\n",
    "    \"type\": \"vehicleV2\", # not case sensitive\n",
    "    \"state\": \"active\",\n",
    "}\n",
    "template_type = \"type=vehicleV2\"\n",
    "\n",
    "agency_devices_url = f\"{base_url}/groups/{ancestor_path}/members/devices\"\n",
    "device_url = f\"{base_url}/devices/{device_id}\"\n",
    "search_url_0 = f\"{base_url}/search?{template_type}\"\n",
    "search_url_1 = f\"{base_url}/search?{urlencode(template_type_dict)}\"\n",
    "\n",
    "print(f\"{agency_devices_url=}\")\n",
    "print(f\"{device_url=}\")\n",
    "print(f\"{search_url_0=}\")\n",
    "print(f\"{search_url_1=}\")\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/vnd.aws-cdf-v2.0+json\",\n",
    "    \"Content-Type\": \"application/vnd.aws-cdf-v2.0+json\",\n",
    "}\n",
    "\n",
    "request_0 = AWSRequest(method=\"GET\", url=search_url_0, headers=headers)\n",
    "SigV4Auth(boto3.Session().get_credentials(), \"execute-api\",\"us-east-1\").add_auth(\n",
    "    request_0\n",
    ")\n",
    "response_0 = URLLib3Session().send(request_0.prepare()).content\n",
    "\n",
    "request_1 = AWSRequest(method=\"GET\", url=search_url_1, headers=headers)\n",
    "SigV4Auth(boto3.Session().get_credentials(), \"execute-api\",\"us-east-1\").add_auth(\n",
    "    request_1\n",
    ")\n",
    "response_1 = URLLib3Session().send(request_1.prepare()).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_aws_sign import AWSV4Sign\n",
    "import boto3\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "from botocore.compat import quote, urlencode\n",
    "from botocore.endpoint import URLLib3Session\n",
    "\n",
    "base_url = \"https://oo9fn5p38b.execute-api.us-east-1.amazonaws.com/Prod\"\n",
    "region_name = \"UnionCity\" # not case sensitive\n",
    "agency_name = \"UnionCity\" # not case sensitive\n",
    "device_id = \"tsp-gtfs-realtime-643\"\n",
    "ancestor_path = quote(f\"/{region_name}/{agency_name}\", safe=\"\")\n",
    "\n",
    "service = \"execute-api\"\n",
    "credentials = boto3.Session().get_credentials()\n",
    "aws_region = os.environ[\"AWS_REGION\"]\n",
    "auth = AWSV4Sign(credentials, aws_region, service)\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/vnd.aws-cdf-v2.0+json\",\n",
    "    \"Content-Type\": \"application/vnd.aws-cdf-v2.0+json\",\n",
    "}\n",
    "\n",
    "device_url = f\"{base_url}/devices/{device_id}\"\n",
    "request_0 = AWSRequest(method=\"GET\", url=device_url, headers=headers)\n",
    "SigV4Auth(boto3.Session().get_credentials(), \"execute-api\",\"us-east-1\").add_auth(\n",
    "    request_0\n",
    ")\n",
    "response_0 = URLLib3Session().send(request_0.prepare()).content\n",
    "\n",
    "auth = AWSV4Sign(credentials, aws_region, service)\n",
    "request_1 = requests.get(device_url, headers=headers, auth=auth)\n",
    "response_1 = request_1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_0)\n",
    "print(response_1)\n",
    "response_0 == response_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = json.loads(response_0, strict=False)\n",
    "print(\"r0\", set(e[\"templateId\"] for e in r0[\"results\"]))\n",
    "\n",
    "r1 = json.loads(response_1, strict=False)\n",
    "print(\"r1\", set(e[\"templateId\"] for e in r1[\"results\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agency:\n",
    "    pass\n",
    "\n",
    "class Region:\n",
    "    pass\n",
    "\n",
    "class Vehicle:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "from botocore.awsrequest import AWSRequest\n",
    "from botocore.endpoint import URLLib3Session\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.compat import urlencode\n",
    "\n",
    "from pydantic import BaseModel, HttpUrl\n",
    "\n",
    "class AssetLibraryBaseModel(BaseModel, abc.ABC):\n",
    "\n",
    "    class Config:\n",
    "        underscore_attrs_are_private = True\n",
    "\n",
    "    _base_url = \"https://oo9fn5p38b.execute-api.us-east-1.amazonaws.com/Prod\"\n",
    "    # _headers = {\n",
    "    #     \"Accept\": \"application/vnd.aws-cdf-v2.0+json\",\n",
    "    #     \"Content-Type\": \"application/vnd.aws-cdf-v2.0+json\",\n",
    "    # }\n",
    "    # _credentials = boto3.Session().get_credentials()\n",
    "\n",
    "    @abc.abstractproperty\n",
    "    def _url(self):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def _send_request(cls, url=None, region_name=None, params=None, data=None, headers=None) -> bytes:\n",
    "        credentials = boto3.Session().get_credentials()\n",
    "        url = url\n",
    "        headers = {\n",
    "            \"Accept\": \"application/vnd.aws-cdf-v2.0+json\",\n",
    "            \"Content-Type\": \"application/vnd.aws-cdf-v2.0+json\",\n",
    "        }\n",
    "        method = \"GET\"\n",
    "        region_name = region_name or \"us-east-1\"\n",
    "\n",
    "        # AWSRequest is unable to handle params with identical keys,\n",
    "        # so manually append to the url\n",
    "        encoded_url = f\"{url}?{urlencode(params)}\" if params else url\n",
    "\n",
    "        # the search API seems to be broken to some degree as only strings without\n",
    "        # encoded characters work, and only with the \\`eq\\` query parameter\n",
    "\n",
    "        request = AWSRequest(method=method, url=encoded_url, headers=headers, data=data)\n",
    "        SigV4Auth(credentials, \"execute-api\", region_name).add_auth(request)\n",
    "        response = URLLib3Session().send(request.prepare())\n",
    "        if response.status_code >= 400 or not response.content:\n",
    "            #! logging.debug(f\"Invalid Asset Library response. url={response.url}, status_code={response.status_code}, headers={response.headers}, content={response.content}\")\n",
    "            raise ValueError(\n",
    "                f\"Invalid Asset Library response. {response.status_code=}, {response.content=}\"\n",
    "            )\n",
    "        return response.content\n",
    "\n",
    "    @classmethod\n",
    "    @abc.abstractmethod\n",
    "    def from_asset_library(cls):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, conint, constr, Field, root_validator, validate_arguments\n",
    "from typing import Literal, List, Union, Dict\n",
    "import requests\n",
    "\n",
    "class IntegrationCom(AssetLibraryBaseModel):\n",
    "    description: str = None\n",
    "    category: Literal[\"device\"]\n",
    "    template_id: Literal[\"integrationcom\"] = Field(alias=\"templateId\")\n",
    "    state: Literal[\"active\"]\n",
    "    device_id: str = Field(alias=\"deviceId\")\n",
    "    # attributes\n",
    "    serial: str\n",
    "    gtt_serial: str = Field(alias=\"gttSerial\")\n",
    "    address_mac: constr(regex=r\"^([0-9A-Fa-f]{2}[:-]){5}([0-9A-Fa-f]{2})$\") = Field(alias=\"addressMAC\")\n",
    "    unique_id: str = Field(alias=\"uniqueId\")\n",
    "    license: Literal[\"pending\", \"inactive\", \"active\", \"decommissioned\", \"transferred\"] = Field(alias=\"preemptionLicense\")\n",
    "    integration: Literal[\"Whelen\", \"Teletrac\", \"gtfs-realtime\", \"Misc.\"]\n",
    "    # groups\n",
    "    region_id: str\n",
    "    agency_id: str\n",
    "    # devices\n",
    "    vehicle_id: str\n",
    "\n",
    "    # used to lazy load related entities\n",
    "    _region: Region = None\n",
    "    _agency: Agency = None\n",
    "    _vehicle: Vehicle = None\n",
    "\n",
    "    @property\n",
    "    def _url(self):\n",
    "        return f\"{self._base_url}/devices/{self.device_id}\"\n",
    "\n",
    "    @classmethod\n",
    "    @validate_arguments\n",
    "    def from_asset_library(cls,\n",
    "        base_url: HttpUrl = None,\n",
    "        device_id: str = None,\n",
    "        filter: Dict[str, str] = None\n",
    "    ):\n",
    "        \"\"\"generate IntegrationCom object by querying asset library\n",
    "\n",
    "        Args:\n",
    "            device_id (str):\n",
    "                asset library deviceId to directly access the device\n",
    "            filter (dict):\n",
    "                dictionary of attributes to use search api. [more on filter params](https://github.com/aws/aws-connected-device-framework/blob/main/source/packages/services/assetlibrary/docs/swagger.yml#L195)\n",
    "        \n",
    "        Note that the search api accepts other comparisons than equals, but this\n",
    "        function forces equality to be used, and only works with strings. This could\n",
    "        be expanded if needed.\n",
    "\n",
    "        Returns:\n",
    "            IntegrationCom: instantiated class object\n",
    "        \"\"\"\n",
    "        # ToDo: get base_url from environment variable\n",
    "        base_url = base_url or \"https://oo9fn5p38b.execute-api.us-east-1.amazonaws.com/Prod\"\n",
    "\n",
    "        if filter:\n",
    "            if device_id:\n",
    "                #! logging.warning(\"device_id and filter both supplied, trying first with device_id\")\n",
    "                try:\n",
    "                    return cls.from_asset_library(base_url=base_url, device_id=device_id)\n",
    "                except ValueError:\n",
    "                    #! logging.warning(\"retrying using filter\")\n",
    "                    pass\n",
    "            # convert to dictionary of attribute fields/values to 2-tuple\n",
    "            # note that the keys and format of filter is not checked\n",
    "            params = [\n",
    "                (\"type\", \"integrationcom\"),\n",
    "                *[(\"eq\", f\"{k}:{v}\") for k, v in filter.items()],\n",
    "            ]\n",
    "            #! logging.debug(f\"attempting to query using search: {filter}\")\n",
    "            # manually parse and re-query since groups/devices\n",
    "            # are not included when using the search api\n",
    "            search_url = f\"{base_url}/search\"\n",
    "            search_dict = json.loads(\n",
    "                cls._send_request(url=search_url, params=params),\n",
    "                strict=False,\n",
    "            )\n",
    "\n",
    "            count = search_dict[\"pagination\"][\"count\"]\n",
    "            if count != 1:\n",
    "                raise ValueError(f\"provided filter returned {'no' if count == 0 else 'multiple'} results\")\n",
    "            # use the discovered device_id to re-query\n",
    "            device_id = search_dict[\"results\"][0][\"deviceId\"]\n",
    "            #! logging.info(f\"found device_id as {device_id}. re-querying to get device\")\n",
    "            return cls.from_asset_library(base_url=base_url, device_id=device_id)\n",
    "\n",
    "        # else, query using device_id\n",
    "        #! logging.debug(f\"attempting to query using device_id: {device_url}\")\n",
    "        device_url = f\"{base_url}/devices/{device_id}\"\n",
    "\n",
    "        return cls.parse_raw(cls._send_request(url=device_url))\n",
    "\n",
    "    @property\n",
    "    def region(self) -> Region:\n",
    "        self._region = self._region or Region.from_asset_library(\n",
    "            group_path=f\"/{self.region_id}\",\n",
    "        )\n",
    "        return self._region\n",
    "\n",
    "    @property\n",
    "    def agency(self) -> Agency:\n",
    "        self._agency = self._agency or Agency.from_asset_library(\n",
    "            group_path=f\"/{self.region_id}/{self.agency_id}\",\n",
    "        )\n",
    "        return self._agency\n",
    "\n",
    "    @property\n",
    "    def vehicle(self) -> Vehicle:\n",
    "        self._vehicle = self._vehicle or Vehicle.from_asset_library(\n",
    "            device_id=self.vehicle_id,\n",
    "        )\n",
    "        return self._vehicle\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def validate_and_flatten_integration_com(cls, values):\n",
    "        # warn of empty response\n",
    "        #! logging.debug(f\"{values=}\")\n",
    "        # get the path to the agency group to parse region/agency\n",
    "        # ToDo: log/handle parsing errors, empty/multiple values, etc.\n",
    "        #! when using postman, there is no intermediate field for out/in, handle both\n",
    "        owned_by = (\n",
    "            values[\"groups\"].get(\"out\") or values[\"groups\"]\n",
    "        ).get(\"ownedby\")[0]\n",
    "\n",
    "        installed_at = (\n",
    "            values[\"devices\"].get(\"in\") or values[\"devices\"]\n",
    "        ).get(\"installedat\")[0]\n",
    "\n",
    "        values.update(\n",
    "            {\n",
    "                \"region_id\": owned_by.split(\"/\")[1],\n",
    "                \"agency_id\": owned_by.split(\"/\")[2],\n",
    "                \"vehicle_id\": installed_at,\n",
    "            }\n",
    "        )\n",
    "        # flatten attributes\n",
    "        values.update(values[\"attributes\"])\n",
    "\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic0 = IntegrationCom.from_asset_library(device_id=\"tsp-gtfs-realtime-643\")\n",
    "ic1 = IntegrationCom.from_asset_library(device_id=\"tsp-gtfs-realtime-543\", filter={\"serial\": 643})\n",
    "\n",
    "print(ic0)\n",
    "print(f\"{(ic0 == ic1)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, conint, constr, Field, root_validator, validate_arguments\n",
    "from typing import Literal, List, Union, Dict\n",
    "import requests\n",
    "\n",
    "class Vehicle(AssetLibraryBaseModel):\n",
    "    description: str = None\n",
    "    category: Literal[\"device\"]\n",
    "    template_id: Literal[\"vehiclev2\"] = Field(alias=\"templateId\")\n",
    "    state: Literal[\"active\"]\n",
    "    device_id: str = Field(alias=\"deviceId\")\n",
    "    # attributes\n",
    "    VID: conint(ge=1, le=9999)\n",
    "    name: str = None\n",
    "    priority: Literal[\"High\", \"Low\"]\n",
    "    type_: str = Field(alias=\"type\", default=None)\n",
    "    class_: str = Field(alias=\"class\")\n",
    "    unique_id: str = Field(alias=\"uniqueId\")\n",
    "    # groups\n",
    "    region_id: str\n",
    "    agency_id: str\n",
    "    # devices\n",
    "    installed_device_ids: List[str]\n",
    "\n",
    "    # used to lazy load related entities\n",
    "    _region: Region = None\n",
    "    _agency: Agency = None\n",
    "    _installed_devices: List[Union[IntegrationCom, str]] = None\n",
    "    _integration_coms: List[IntegrationCom] = None\n",
    "\n",
    "    @property\n",
    "    def _url(self):\n",
    "        return f\"{self._base_url}/devices/{self.device_id}\"\n",
    "\n",
    "    @classmethod\n",
    "    @validate_arguments\n",
    "    def from_asset_library(cls,\n",
    "        base_url: HttpUrl = None,\n",
    "        device_id: str = None,\n",
    "        filter: Dict[str, str] = None\n",
    "    ):\n",
    "        \"\"\"generate Vehicle object by querying asset library\n",
    "\n",
    "        Args:\n",
    "            device_id (str):\n",
    "                asset library deviceId to directly access the device\n",
    "            filter (dict):\n",
    "                dictionary of attributes to use search api. [more on filter params](https://github.com/aws/aws-connected-device-framework/blob/main/source/packages/services/assetlibrary/docs/swagger.yml#L195)\n",
    "        \n",
    "        Note that the search api accepts other comparisons than equals, but this\n",
    "        function forces equality to be used, and only works with strings. This could\n",
    "        be expanded if needed.\n",
    "\n",
    "        Returns:\n",
    "            Vehicle: instantiated class object\n",
    "        \"\"\"\n",
    "        # ToDo: get base_url from environment variable\n",
    "        base_url = base_url or \"https://oo9fn5p38b.execute-api.us-east-1.amazonaws.com/Prod\"\n",
    "\n",
    "        if filter:\n",
    "            if device_id:\n",
    "                #! logging.warning(\"device_id and filter both supplied, trying first with device_id\")\n",
    "                try:\n",
    "                    return cls.from_asset_library(base_url=base_url, device_id=device_id)\n",
    "                except ValueError:\n",
    "                    #! logging.warning(\"retrying using filter\")\n",
    "                    pass\n",
    "            # convert to dictionary of attribute fields/values to 2-tuple\n",
    "            # note that the keys and format of filter is not checked\n",
    "            params = [\n",
    "                (\"type\", \"vehiclev2\"),\n",
    "                *[(\"eq\", f\"{k}:{v}\") for k, v in filter.items()],\n",
    "            ]\n",
    "            \n",
    "            #! logging.debug(f\"attempting to query using search: {filter}\")\n",
    "            # manually parse and re-query since groups/devices\n",
    "            # are not included when using the search api\n",
    "            search_url = f\"{base_url}/search\"\n",
    "            search_dict = json.loads(\n",
    "                cls._send_request(url=search_url, params=params),\n",
    "                strict=False,\n",
    "            )\n",
    "\n",
    "            count = search_dict[\"pagination\"][\"count\"]\n",
    "            if count != 1:\n",
    "                raise ValueError(f\"provided filter returned {'no' if count == 0 else 'multiple'} results\")\n",
    "            # use the discovered device_id to re-query\n",
    "            device_id = search_dict[\"results\"][0][\"deviceId\"]\n",
    "            #! logging.info(f\"found device_id as {device_id}. re-querying to get device\")\n",
    "            return cls.from_asset_library(base_url=base_url, device_id=device_id)\n",
    "\n",
    "        # else, query using device_id\n",
    "        #! logging.debug(f\"attempting to query using device_id: {device_url}\")\n",
    "        device_url = f\"{base_url}/devices/{device_id}\"\n",
    "\n",
    "        return cls.parse_raw(cls._send_request(url=device_url))\n",
    "\n",
    "    @property\n",
    "    def region(self) -> Region:\n",
    "        self._region = self._region or Region.from_asset_library(\n",
    "            group_path=f\"/{self.region_id}\",\n",
    "        )\n",
    "        return self._region\n",
    "\n",
    "    @property\n",
    "    def agency(self) -> Agency:\n",
    "        self._agency = self._agency or Agency.from_asset_library(\n",
    "            group_path=f\"/{self.region_id}/{self.agency_id}\",\n",
    "        )\n",
    "        return self._agency\n",
    "\n",
    "    @property\n",
    "    def installed_devices(self) -> List[Union[IntegrationCom, str]]:\n",
    "        # note that this stores the actual IntegrationCom entities, but only the\n",
    "        # device_id for other devices. this could be expanded once other models exist\n",
    "        def integration_com_or_device_id(device_id: str) -> Union[IntegrationCom, str]:\n",
    "            try:\n",
    "                return IntegrationCom.from_asset_library(device_id=device_id)\n",
    "            except ValueError as e:\n",
    "                #! logging.debug(e)\n",
    "                return device_id\n",
    "\n",
    "        self._installed_devices = self._installed_devices or [\n",
    "            integration_com_or_device_id(d) for d in self.installed_device_ids\n",
    "        ]\n",
    "        return self._installed_devices\n",
    "\n",
    "    @property\n",
    "    def integration_com(self) -> IntegrationCom:\n",
    "        # get installed IntegrationCom device, assert singular entity\n",
    "        self._integration_coms = self._integration_coms or [\n",
    "            d for d in self.installed_devices if isinstance(d, IntegrationCom)\n",
    "        ]\n",
    "        assert len(self._integration_coms) == 1\n",
    "        return self._integration_coms[0]\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def validate_and_flatten_vehicle(cls, values):\n",
    "        # warn of empty response\n",
    "        #! logging.debug(f\"{values=}\")\n",
    "        # get the path to the agency group to parse region/agency\n",
    "        # ToDo: log/handle parsing errors, empty/multiple values, etc.\n",
    "        #! when using postman, there is no intermediate field for out/in, handle both\n",
    "        owned_by = (\n",
    "            values[\"groups\"].get(\"out\") or values[\"groups\"]\n",
    "        ).get(\"ownedby\")[0]\n",
    "\n",
    "        installed_at = (\n",
    "            values[\"devices\"].get(\"out\") or values[\"devices\"]\n",
    "        ).get(\"installedat\")\n",
    "\n",
    "        values.update(\n",
    "            {\n",
    "                \"region_id\": owned_by.split(\"/\")[1],\n",
    "                \"agency_id\": owned_by.split(\"/\")[2],\n",
    "                \"installed_device_ids\": installed_at,\n",
    "            }\n",
    "        )\n",
    "        # flatten attributes\n",
    "        values.update(values[\"attributes\"])\n",
    "\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = Vehicle.from_asset_library(device_id=\"union-city-vehicle-643\")\n",
    "v1 = Vehicle.from_asset_library(device_id=\"union-city-vehicle-543\", filter={\"name\": \"vehicle-643\"})\n",
    "\n",
    "#! It seems like it is not possible to search using VID because \"eq\" requires the field\n",
    "#! to be a string type, but VID is a number. Using gte, lte, etc. timed out after 30s\n",
    "\n",
    "print(v0)\n",
    "print(f\"{(v0 == v1)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, conint, constr, Field, root_validator, validate_arguments\n",
    "from typing import Literal, List, Union, Dict\n",
    "import requests\n",
    "\n",
    "class Agency(AssetLibraryBaseModel):\n",
    "    description: str = None\n",
    "    category: Literal[\"group\"]\n",
    "    template_id: Literal[\"agency\"] = Field(alias=\"templateId\")\n",
    "    name: str\n",
    "    group_path: str = Field(alias=\"groupPath\")\n",
    "    parent_path: str = Field(alias=\"parentPath\")\n",
    "    # attributes\n",
    "    city: str\n",
    "    state: str\n",
    "    timezone: Literal[\"Central\", \"Mountain\", \"Eastern\", \"Pacific\", \"Arizona\"]\n",
    "    agency_code: conint(ge=1, le=254) = Field(alias=\"agencyCode\")\n",
    "    unique_id: str = Field(alias=\"agencyID\") # note name change\n",
    "    vps_cert_id: str = Field(alias=\"vpsCertId\")\n",
    "    cert2100_id: str = Field(alias=\"Cert2100Id\", default=None)\n",
    "    priority: Literal[\"High\", \"Low\"]\n",
    "    cms_id: str = Field(alias=\"CMSId\", default=None)\n",
    "    ca_cert_id: str = Field(alias=\"caCertId\")\n",
    "    display_name: str = Field(alias=\"displayName\", default=None)\n",
    "    # groups\n",
    "    region_id: str\n",
    "    # member devices requires querying\n",
    "\n",
    "    # used to lazy load related entities\n",
    "    _region: Region = None\n",
    "    _devices: List[Union[Vehicle, IntegrationCom, str]] = None\n",
    "    _integration_coms: List[IntegrationCom] = None\n",
    "    _vehicles: List[Vehicle] = None\n",
    "\n",
    "    @property\n",
    "    def _url(self):\n",
    "        return f\"{self._base_url}/groups/{quote(self.group_path, safe='')}\"\n",
    "\n",
    "    @classmethod\n",
    "    @validate_arguments\n",
    "    def from_asset_library(cls,\n",
    "        base_url: HttpUrl = None,\n",
    "        group_path: str = None,\n",
    "        filter: Dict[str, str] = None\n",
    "    ):\n",
    "        \"\"\"generate Agency object by querying asset library\n",
    "\n",
    "        Args:\n",
    "            group_path (str):\n",
    "                asset library groupPath to directly access the group\n",
    "            filter (dict):\n",
    "                dictionary of attributes to use search api. [more on filter params](https://github.com/aws/aws-connected-device-framework/blob/main/source/packages/services/assetlibrary/docs/swagger.yml#L195)\n",
    "        \n",
    "        Note that the search api accepts other comparisons than equals, but this\n",
    "        function forces equality to be used, and only works with strings. This could\n",
    "        be expanded if needed.\n",
    "\n",
    "        Returns:\n",
    "            Agency: instantiated class object\n",
    "        \"\"\"\n",
    "        # ToDo: get base_url from environment variable\n",
    "        base_url = base_url or \"https://oo9fn5p38b.execute-api.us-east-1.amazonaws.com/Prod\"\n",
    "        # urlencode the group_path to handle /\n",
    "        group_path = quote(group_path, safe=\"%\") if group_path else None\n",
    "\n",
    "        if filter:\n",
    "            if group_path:\n",
    "                #! logging.warning(\"group_path and filter both supplied, trying first with group_path\")\n",
    "                try:\n",
    "                    return cls.from_asset_library(base_url=base_url, group_path=group_path)\n",
    "                except ValueError:\n",
    "                    #! logging.warning(\"retrying using filter\")\n",
    "                    pass\n",
    "            # convert to dictionary of attribute fields/values to 2-tuple\n",
    "            # note that the keys and format of filter is not checked\n",
    "            params = [\n",
    "                (\"type\", \"agency\"),\n",
    "                *[(\"eq\", f\"{k}:{v}\") for k, v in filter.items()],\n",
    "            ]\n",
    "            #! logging.debug(f\"attempting to query using search: {filter}\")\n",
    "            # manually parse and re-query since groups/devices\n",
    "            # are not included when using the search api\n",
    "            search_url = f\"{base_url}/search\"\n",
    "            search_dict = json.loads(\n",
    "                cls._send_request(url=search_url, params=params),\n",
    "                strict=False,\n",
    "            )\n",
    "\n",
    "            count = search_dict[\"pagination\"][\"count\"]\n",
    "            if count != 1:\n",
    "                raise ValueError(f\"provided filter returned {'no' if count == 0 else 'multiple'} results\")\n",
    "            # use the discovered group_path to re-query\n",
    "            group_path = search_dict[\"results\"][0][\"groupPath\"]\n",
    "            #! logging.info(f\"found group_path as {group_path}. re-querying to get group\")\n",
    "            return cls.from_asset_library(base_url=base_url, group_path=group_path)\n",
    "\n",
    "        # else, query using group_path\n",
    "        #! logging.debug(f\"attempting to query using group_path: {group_url}\")\n",
    "        group_url = f\"{base_url}/groups/{group_path}\"\n",
    "\n",
    "        return cls.parse_raw(cls._send_request(url=group_url))\n",
    "\n",
    "    @property\n",
    "    def region(self) -> Region:\n",
    "        self._region = self._region or Region.from_asset_library(\n",
    "            group_path=self.parent_path,\n",
    "        )\n",
    "        return self._region\n",
    "\n",
    "    @property\n",
    "    def devices(self) -> List[Union[Vehicle, IntegrationCom, str]]:\n",
    "        # note that this stores the actual Vehicle/IntegrationCom entities, but only the\n",
    "        # device_id for other devices. this could be expanded once other models exist\n",
    "        if not self._devices:\n",
    "            members_url = f\"{self._url}/members/devices\"\n",
    "            members = json.loads(\n",
    "                self._send_request(url=members_url),\n",
    "                strict=False,\n",
    "            )\n",
    "            self._devices = [\n",
    "                Vehicle.from_asset_library(device_id=d[\"deviceId\"])\n",
    "                if d[\"templateId\"].lower() == \"vehiclev2\"\n",
    "                else IntegrationCom.from_asset_library(device_id=d[\"deviceId\"])\n",
    "                if d[\"templateId\"].lower() == \"integrationcom\"\n",
    "                else d[\"deviceId\"]\n",
    "                for d in members[\"results\"]\n",
    "            ]\n",
    "        return self._devices\n",
    "\n",
    "    @property\n",
    "    def vehicles(self) -> List[Vehicle]:\n",
    "        # get Vehicle devices from member devices\n",
    "        self._vehicles = self._vehicles or [\n",
    "            d for d in self.devices if isinstance(d, Vehicle)\n",
    "        ]\n",
    "        return self._vehicles\n",
    "\n",
    "    @property\n",
    "    def integration_coms(self) -> List[IntegrationCom]:\n",
    "        # get IntegrationCom devices from member devices\n",
    "        self._integration_coms = self._integration_coms or [\n",
    "            d for d in self.devices if isinstance(d, IntegrationCom)\n",
    "        ]\n",
    "        return self._integration_coms\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def validate_and_flatten_agency(cls, values):\n",
    "        # warn of empty response\n",
    "        #! logging.debug(f\"{values=}\")\n",
    "        # get parentPath to parse region\n",
    "        values[\"region_id\"] = values[\"parentPath\"].split(\"/\")[-1]\n",
    "\n",
    "        # flatten attributes\n",
    "        values.update(values[\"attributes\"])\n",
    "\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case insensitive\n",
    "region_name = \"UnionCity\"\n",
    "agency_name = \"uNiOncITy\"\n",
    "group_path = f\"/{region_name}/{agency_name}\"\n",
    "group_path_encoded = quote(group_path, safe=\"\")\n",
    "\n",
    "a0 = Agency.from_asset_library(group_path=group_path)\n",
    "a1 = Agency.from_asset_library(group_path=group_path_encoded)\n",
    "a2 = Agency.from_asset_library(filter={\"displayName\": \"UnionCity\"})\n",
    "\n",
    "print(a0)\n",
    "print(f\"{(a0 == a1 == a2)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, conint, constr, Field, root_validator, validate_arguments\n",
    "from typing import Literal, List, Union, Dict\n",
    "import requests\n",
    "\n",
    "class Region(AssetLibraryBaseModel):\n",
    "    description: str = None\n",
    "    category: Literal[\"group\"]\n",
    "    template_id: Literal[\"region\"] = Field(alias=\"templateId\")\n",
    "    name: str\n",
    "    group_path: str = Field(alias=\"groupPath\")\n",
    "    parent_path: Literal[\"/\"] = Field(alias=\"parentPath\")\n",
    "    # attributes\n",
    "    ca_cert_id: str = Field(alias=\"caCertId\")\n",
    "    unique_id: str = Field(alias=\"regionGUID\") # note name change\n",
    "    display_name: str = Field(alias=\"displayName\", default=None)\n",
    "    # child groups requires querying\n",
    "\n",
    "    # used to lazy load related entities\n",
    "    _agencies: List[Agency] = None\n",
    "    # region has no child devices\n",
    "\n",
    "    @property\n",
    "    def _url(self):\n",
    "        return f\"{self._base_url}/groups/{quote(self.group_path, safe='')}\"\n",
    "\n",
    "    @classmethod\n",
    "    @validate_arguments\n",
    "    def from_asset_library(cls,\n",
    "        base_url: HttpUrl = None,\n",
    "        group_path: str = None,\n",
    "        filter: Dict[str, str] = None\n",
    "    ):\n",
    "        \"\"\"generate Region object by querying asset library\n",
    "\n",
    "        Args:\n",
    "            group_path (str):\n",
    "                asset library groupPath to directly access the group\n",
    "            filter (dict):\n",
    "                dictionary of attributes to use search api. [more on filter params](https://github.com/aws/aws-connected-device-framework/blob/main/source/packages/services/assetlibrary/docs/swagger.yml#L195)\n",
    "        \n",
    "        Note that the search api accepts other comparisons than equals, but this\n",
    "        function forces equality to be used, and only works with strings. This could\n",
    "        be expanded if needed.\n",
    "\n",
    "        Returns:\n",
    "            Region: instantiated class object\n",
    "        \"\"\"\n",
    "        # ToDo: get base_url from environment variable\n",
    "        base_url = base_url or \"https://oo9fn5p38b.execute-api.us-east-1.amazonaws.com/Prod\"\n",
    "        # urlencode the group_path to handle /\n",
    "        group_path = quote(group_path, safe=\"%\") if group_path else None\n",
    "\n",
    "        if filter:\n",
    "            if group_path:\n",
    "                #! logging.warning(\"group_path and filter both supplied, trying first with group_path\")\n",
    "                try:\n",
    "                    return cls.from_asset_library(base_url=base_url, group_path=group_path)\n",
    "                except ValueError:\n",
    "                    #! logging.warning(\"retrying using filter\")\n",
    "                    pass\n",
    "            # convert to dictionary of attribute fields/values to 2-tuple\n",
    "            # note that the keys and format of filter is not checked\n",
    "            params = [\n",
    "                (\"type\", \"region\"),\n",
    "                *[(\"eq\", f\"{k}:{v}\") for k, v in filter.items()],\n",
    "            ]\n",
    "            #! logging.debug(f\"attempting to query using search: {filter}\")\n",
    "            # manually parse and re-query since groups/devices\n",
    "            # are not included when using the search api\n",
    "            search_url = f\"{base_url}/search\"\n",
    "            search_dict = json.loads(\n",
    "                cls._send_request(url=search_url, params=params),\n",
    "                strict=False,\n",
    "            )\n",
    "\n",
    "            count = search_dict[\"pagination\"][\"count\"]\n",
    "            if count != 1:\n",
    "                raise ValueError(f\"provided filter returned {'no' if count == 0 else 'multiple'} results\")\n",
    "            # use the discovered group_path to re-query\n",
    "            group_path = search_dict[\"results\"][0][\"groupPath\"]\n",
    "            #! logging.info(f\"found group_path as {group_path}. re-querying to get group\")\n",
    "            return cls.from_asset_library(base_url=base_url, group_path=group_path)\n",
    "\n",
    "        # else, query using group_path\n",
    "        #! logging.debug(f\"attempting to query using group_path: {group_url}\")\n",
    "        group_url = f\"{base_url}/groups/{group_path}\"\n",
    "\n",
    "        return cls.parse_raw(cls._send_request(url=group_url))\n",
    "\n",
    "    @property\n",
    "    def agencies(self) -> List[Agency]:\n",
    "        if not self._agencies:\n",
    "            members_url = f\"{self._url}/members/groups\"\n",
    "            members = json.loads(\n",
    "                self._send_request(url=members_url),\n",
    "                strict=False,\n",
    "            )\n",
    "            self._agencies = [\n",
    "                Agency.from_asset_library(group_path=group[\"groupPath\"])\n",
    "                for group in members[\"results\"]\n",
    "                if group[\"templateId\"].lower() == \"agency\"\n",
    "            ]\n",
    "        return self._agencies\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def validate_and_flatten_agency(cls, values):\n",
    "        # warn of empty response\n",
    "        #! logging.debug(f\"{values=}\")\n",
    "        # flatten attributes\n",
    "        values.update(values[\"attributes\"])\n",
    "\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case insensitive\n",
    "region_name = \"unioncity\"\n",
    "group_path = f\"/{region_name}\"\n",
    "group_path_encoded = quote(group_path, safe=\"\")\n",
    "\n",
    "r0 = Region.from_asset_library(group_path=group_path)\n",
    "r1 = Region.from_asset_library(group_path=group_path_encoded)\n",
    "r2 = Region.from_asset_library(filter={\"displayName\": \"UnionCity\"})\n",
    "\n",
    "print(r0)\n",
    "print(f\"{(r0 == r1 == r2)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(ic0.vehicle == v0)=}\")\n",
    "print(f\"{(v0.integration_com == ic0)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(ic0.agency == v0.agency == a0 == r0.agencies[0])=}\")\n",
    "print(f\"{(ic0.region == v0.region == a0.region == r0)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(ic0 in a0.integration_coms)=}\")\n",
    "print(f\"{(v0 in a0.vehicles)=}\")\n",
    "print(f\"{all(d in a0.devices for d in [ic0, ic1, v0, v1])=}\")\n",
    "print(f\"{all(d in r0.agencies[0].devices for d in [ic0, ic1, v0, v1])=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://oo9fn5p38b.execute-api.us-east-1.amazonaws.com/Prod\"\n",
    "\n",
    "print(f\"{base_url}/groups/{quote(r0.group_path, safe='')}/members/groups\")\n",
    "print(f\"{r0._url}/members/groups\")\n",
    "print(r0._url)\n",
    "print(r0._base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, ClassVar, ForwardRef\n",
    "import abc\n",
    "\n",
    "class GroupBaseModel(BaseModel):\n",
    "    description: str = None\n",
    "    category: Literal[\"group\"]\n",
    "    # template_id: ClassVar[str] = \"test\"\n",
    "    # template_id = \"test\"\n",
    "    # template_id: Literal[\"region\", \"agency\"] = Field(alias=\"templateId\")\n",
    "    _template_id: str = Field(alias=\"templateId\", const=True, default=ForwardRef(\"template_id\"))\n",
    "    name: str\n",
    "    group_path: str = Field(alias=\"groupPath\")\n",
    "    parent_path: Literal[\"/\"] = Field(alias=\"parentPath\")\n",
    "\n",
    "    @property\n",
    "    def _url(self):\n",
    "        return f\"{self._base_url}/groups/{quote(self.group_path, safe='')}\"\n",
    "\n",
    "    @classmethod\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def template_id(self) -> str:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "class Region(GroupBaseModel):\n",
    "    template_id: ClassVar[str] = \"region\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsp_gtfs_realtime.core.data_model import Region\n",
    "\n",
    "ic_device_id = \"tsp-gtfs-realtime-643\"\n",
    "invalid_ic_device_id = \"tsp-gtfs-realtime-543\"\n",
    "ic_serial_search_attributes = {\"serial\": 643}\n",
    "\n",
    "vehicle_device_id = \"union-city-vehicle-643\"\n",
    "invalid_vehicle_device_id = \"union-city-vehicle-543\"\n",
    "vehicle_name_search_attributes = {\"name\": \"vehicle-643\"}\n",
    "\n",
    "# case insensitive\n",
    "region_name = \"UnionCity\"\n",
    "agency_name = \"uNiOncITy\"\n",
    "region_path = f\"/{region_name}\"\n",
    "agency_path = f\"/{region_name}/{agency_name}\"\n",
    "display_name_search_attributes = {\"displayName\": \"UnionCity\"}\n",
    "\n",
    "region = Region.from_asset_library(group_path=region_path)\n",
    "region1 = Region.from_asset_library(group_path=agency_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_address = \"00:00:00:d0:06:43\"\n",
    "mac_address = \"FF:FF:FF:7F:FF:FF\"\n",
    "mac_address_1 = mac_address.replace(\":\", \"\")[-6:]\n",
    "mac_address_2 = bin(int(mac_address_1, 16))[2:].zfill(24)\n",
    "\n",
    "orrer = f\"{8388608:024b}\"\n",
    "mac_address_3 = \"\"\n",
    "\n",
    "for i in range(0, 24):\n",
    "    mac_address_3 += str(int(orrer[i]) | int(mac_address_2[i]))\n",
    "\n",
    "mac_address_4 = int(mac_address_3, 2)\n",
    "print(mac_address)\n",
    "print(mac_address_1)\n",
    "print(mac_address_2)\n",
    "print(orrer)\n",
    "print(mac_address_3)\n",
    "print(mac_address_4)\n",
    "print(hex(mac_address_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(mac_address_4).to_bytes(4, byteorder=\"little\")\n",
    "int(int(mac_address_4).to_bytes(4, byteorder=\"little\")).to_bytes(4, byteorder=\"little\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "class R(BaseModel):\n",
    "    template_id: Literal[\"region\"] = Field(alias=\"templateId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region.template_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! ToDo: continue\n",
    "class DeviceBaseModel(AssetLibraryBaseModel):\n",
    "    description: str = None\n",
    "    category: Literal[\"group\"]\n",
    "    template_id: str = Field(alias=\"templateId\")\n",
    "    name: str\n",
    "    group_path: str = Field(alias=\"groupPath\")\n",
    "    parent_path: str = Field(alias=\"parentPath\")\n",
    "\n",
    "    @classmethod\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def _template_id(self) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @validator(\"template_id\")\n",
    "    def validate_template_id(cls, value):\n",
    "        if value != cls._template_id:\n",
    "            raise ValueError(\n",
    "                f\"template_id does not match; expected='{cls._template_id}', given='{value}'\"\n",
    "            )\n",
    "        return value\n",
    "\n",
    "    @property\n",
    "    def _url(self):\n",
    "        return f\"{self._base_url}/groups/{quote(self.group_path, safe='')}\"\n",
    "\n",
    "    @classmethod\n",
    "    @validate_arguments\n",
    "    def from_asset_library(\n",
    "        cls,\n",
    "        base_url: HttpUrl = None,\n",
    "        group_path: str = None,\n",
    "        search_attributes: Dict[str, str] = None,\n",
    "    ):\n",
    "        f\"\"\"generate {cls.__name__} object by querying asset library\n",
    "\n",
    "        Args:\n",
    "            group_path (str):\n",
    "                asset library groupPath to directly access the group\n",
    "            search_attributes (dict):\n",
    "                dictionary of attributes to use search api. [more on filter params](https://github.com/aws/aws-connected-device-framework/blob/main/source/packages/services/assetlibrary/docs/swagger.yml#L195)\n",
    "\n",
    "        Note that the search api accepts other comparisons than equals, but this\n",
    "        function forces equality to be used, and only works with strings. This could\n",
    "        be expanded if needed.\n",
    "\n",
    "        Returns:\n",
    "            {cls.__name__}: instantiated class object\n",
    "        \"\"\"\n",
    "        # ToDo: get base_url from environment variable\n",
    "        base_url = (\n",
    "            base_url or \"https://oo9fn5p38b.execute-api.us-east-1.amazonaws.com/Prod\"\n",
    "        )\n",
    "        # urlencode the group_path to handle /\n",
    "        group_path = quote(group_path, safe=\"%\") if group_path else None\n",
    "\n",
    "        if search_attributes:\n",
    "            if group_path:\n",
    "                logging.warning(\n",
    "                    \"group_path and search_attributes both supplied, trying first with group_path\"\n",
    "                )\n",
    "                try:\n",
    "                    return cls.from_asset_library(\n",
    "                        base_url=base_url, group_path=group_path\n",
    "                    )\n",
    "                except ValueError:\n",
    "                    logging.warning(\n",
    "                        f\"unable to query {group_path=} retrying using search_attributes\"\n",
    "                    )\n",
    "            # convert to dictionary of attribute fields/values to 2-tuple\n",
    "            # note that the keys and format of search_attributes is not checked\n",
    "            params = [\n",
    "                (\"type\", cls._template_id),\n",
    "                *[(\"eq\", f\"{k}:{v}\") for k, v in search_attributes.items()],\n",
    "            ]\n",
    "            logging.debug(f\"attempting to query using search: {search_attributes}\")\n",
    "            # manually parse and re-query since groups/devices\n",
    "            # are not included when using the search api\n",
    "            search_url = f\"{base_url}/search\"\n",
    "            search_dict = json.loads(\n",
    "                cls._send_request(url=search_url, params=params),\n",
    "                strict=False,\n",
    "            )\n",
    "\n",
    "            count = search_dict[\"pagination\"][\"count\"]\n",
    "            if count != 1:\n",
    "                raise ValueError(\n",
    "                    f\"provided search_attributes returned {'no' if count == 0 else 'multiple'} results\"\n",
    "                )\n",
    "            # use the discovered group_path to re-query\n",
    "            group_path = search_dict[\"results\"][0][\"groupPath\"]\n",
    "            logging.info(f\"found group_path as {group_path}. re-querying to get group\")\n",
    "            return cls.from_asset_library(base_url=base_url, group_path=group_path)\n",
    "\n",
    "        # else, query using group_path\n",
    "        group_url = f\"{base_url}/groups/{group_path}\"\n",
    "        logging.debug(f\"attempting to query using group_path: {group_url}\")\n",
    "\n",
    "        return cls.parse_raw(cls._send_request(url=group_url))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env_scp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb139083b99984a32d366ad2aa53efbb506e0a119e9a321fdb178cf9a4b1f5a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
