{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will show how to get trip_update data and test agencies to check whether they provide lateness estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripDelayData:\n",
    "    def __init__(\n",
    "        # self, delay, stop_time_updates, timestamp=None, trip_id=None, route_id=None, vehicle_id=None\n",
    "        self, delay, stop_time_updates, timestamp=None, trip_id=None\n",
    "    ):\n",
    "        if trip_id:\n",
    "            self.trip_id = trip_id\n",
    "        self.timestamp = datetime.fromtimestamp(timestamp) if timestamp else pd.NaT\n",
    "        self.delay = delay\n",
    "        # keys: [\"stop_sequence\", \"stop_id\",\n",
    "        #        \"arrival_delay\", \"arrival_time\", \"arrival_uncertainty\",\n",
    "        #        \"departure_delay\", \"departure_time\", \"departure_uncertainty\"]\n",
    "        self.stop_time_updates = []\n",
    "        for st in stop_time_updates:\n",
    "            self.stop_time_updates.append(\n",
    "                {\n",
    "                    **({\"stop_id\": st[\"stop_id\"]} if \"stop_id\" in st else {}),\n",
    "                    **({\"stop_sequence\": st[\"stop_sequence\"]} if \"stop_sequence\" in st else {}),\n",
    "                    \"arrival_time\": datetime.fromtimestamp(st[\"arrival_time\"]) if \"arrival_time\" in st else pd.NaT,\n",
    "                    \"arrival_delay\": st.get(\"arrival_delay\"),\n",
    "                    **({\"arrival_uncertainty\": st[\"arrival_uncertainty\"]} if \"arrival_uncertainty\" in st else {}),\n",
    "                    \"departure_time\": datetime.fromtimestamp(st[\"departure_time\"]) if \"departure_time\" in st else pd.NaT,\n",
    "                    \"departure_delay\": st.get(\"departure_delay\"),\n",
    "                    **({\"departure_uncertainty\": st[\"departure_uncertainty\"]} if \"departure_uncertainty\" in st else {}),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # self.stop_time_updates = [\n",
    "        #     {\n",
    "        #         \"stop_id\": st.get(\"stop_id\"),\n",
    "        #         \"stop_sequence\": st.get(\"stop_sequence\"),\n",
    "        #         \"arrival_time\": (\n",
    "        #             datetime.fromtimestamp(st[\"arrival_time\"])\n",
    "        #             if st.get(\"arrival_time\")\n",
    "        #             else pd.NaT\n",
    "        #         ),\n",
    "        #         \"arrival_delay\": st.get(\"arrival_delay\"),\n",
    "        #         \"arrival_uncertainty\": st.get(\"arrival_uncertainty\"),\n",
    "        #         \"departure_time\": (\n",
    "        #             datetime.fromtimestamp(st[\"departure_time\"])\n",
    "        #             if st.get(\"departure_time\")\n",
    "        #             else pd.NaT\n",
    "        #         ),\n",
    "        #         \"departure_delay\": st.get(\"departure_delay\"),\n",
    "        #         \"departure_uncertainty\": st.get(\"departure_uncertainty\"),\n",
    "        #     }\n",
    "        #     for st in stop_time_updates\n",
    "        # ]\n",
    "    \n",
    "    def flatten(self):\n",
    "        # un-nest the stop time updates\n",
    "        parent_vars = {k:v for k, v in vars(self).items() if k != \"stop_time_updates\"}\n",
    "        return [dict(parent_vars, **st) for st in self.stop_time_updates]\n",
    "\n",
    "    def __repr__(self):\n",
    "        type_name = type(self).__name__\n",
    "        attr_string = \", \".join([f\"{k}={v!r}\" for k, v in vars(self).items()])\n",
    "        return f\"{type_name}({attr_string})\"\n",
    "\n",
    "    def __str__(self):\n",
    "        type_name = type(self).__name__\n",
    "        max_attr_len = len(max(vars(self), key=len))\n",
    "        attr_strings = [f\"{k:{max_attr_len}}  {v}\" for k, v in vars(self).items()]\n",
    "        return \"\\n  \".join([type_name] + attr_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poll the trip updates the GTFS Realtime TripUpdates feed directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsp_gtfs_realtime.gtfs_realtime_api_poller import GTFSRealtimeAPIPoller, GTFSRealtimeConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point `config_folder` to a folder with agency json config files, or set `config_files` manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all config files\n",
    "config_folder = Path(\"../tsp_gtfs_realtime/config/agencies\")\n",
    "config_files = sorted(config_folder.glob(\"*.json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poll each feed `num_samples` times\n",
    "\n",
    "Instantiating the pollers outside the loop allows them each to manage the polling rate. This could be parallelized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pollers for each feed\n",
    "agency_gtfs_realtime_api_poller = {\n",
    "    config_file.stem: GTFSRealtimeAPIPoller(GTFSRealtimeConfig.from_inputs(config_file=config_file)) for config_file in config_files\n",
    "}\n",
    "agency_trip_delay_data = {config_file.stem: [] for config_file in config_files}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "\n",
    "for sample_idx in range(num_samples):\n",
    "    for agency, gtfs_realtime_api_poller in agency_gtfs_realtime_api_poller.items():\n",
    "        print(f\"Sample {sample_idx}, Polling {agency}\")\n",
    "        try:\n",
    "            gtfs_realtime_api_poller.poll_trip_updates()\n",
    "            agency_trip_delay_data[agency].extend(\n",
    "                [\n",
    "                    TripDelayData(\n",
    "                        trip_id=fields.get(\"trip_id\"),\n",
    "                        timestamp=fields.get(\"timestamp\"),\n",
    "                        delay=fields.get(\"delay\"),\n",
    "                        stop_time_updates=fields.get(\"stop_time_updates\"),\n",
    "                    )\n",
    "                    for _, fields in gtfs_realtime_api_poller.trip_updates\n",
    "                ]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Error, skipping {agency} {sample_idx}\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case some agency never got good data delete it\n",
    "for agency in list(agency_trip_delay_data):\n",
    "    if not agency_trip_delay_data[agency]:\n",
    "        print(f\"{agency} never received good data, deleting\")\n",
    "        del agency_gtfs_realtime_api_poller[agency]\n",
    "        del agency_trip_delay_data[agency]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agency_trip_delay_data = {\n",
    "    agency: pd.DataFrame(\n",
    "        chain(*[trip_delay.flatten() for trip_delay in trip_delays])\n",
    "    )\n",
    "    for agency, trip_delays in agency_trip_delay_data.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can also be saved to a csv file for further investigation or just appending data from different polling times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_save_csv = True\n",
    "should_append = True\n",
    "\n",
    "csv_folder = Path(\"./output/csv_trip_delay/\")\n",
    "csv_folder.mkdir(parents=True, exist_ok=True)\n",
    "if should_save_csv:\n",
    "    for agency in df_agency_trip_delay_data.keys():\n",
    "        csv_file = csv_folder.joinpath(f\"{agency}.csv\")\n",
    "        if should_append and csv_file.is_file():\n",
    "            df_agency_trip_delay_data[agency] = pd.concat(\n",
    "                [pd.read_csv(csv_file), df_agency_trip_delay_data[agency]],\n",
    "                ignore_index=True\n",
    "            ).drop_duplicates()\n",
    "        df_agency_trip_delay_data[agency].to_csv(csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a markdown summary of the agencies\n",
    "\n",
    "This notes if any fields are missing, splitting these agencies to another section\n",
    "\n",
    "It also notes the location with a link to the developer resources provided by the agency, and makes a table from a sample excerpt of the data\n",
    "\n",
    "This is mainly to make copying to confluence easy, which can either be pasted directly, or require right-click > \"Paste and Match Style\" while editing a document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agency, df_trip_delay_data in df_agency_trip_delay_data.items():\n",
    "    # only rows with arrival or departure delay populated\n",
    "    df_delays = df_trip_delay_data.dropna(how=\"all\", subset=[\"arrival_delay\", \"departure_delay\"])\n",
    "    # rows with different arrival and departure time (not including nans)\n",
    "    df_different_delays = df_delays[df_delays[\"arrival_delay\"] != df_delays[\"departure_delay\"]].dropna(how=\"any\", subset=[\"arrival_delay\", \"departure_delay\"])\n",
    "    # rows with only arrival or departure, but not both\n",
    "    df_either_delays = df_delays[df_delays[[\"arrival_delay\", \"departure_delay\"]].isna().any(axis=1)]\n",
    "\n",
    "    if \"arrival_time\" not in df_trip_delay_data:\n",
    "        df_times = df_either_times = df_trip_delay_data.dropna(how=\"all\", subset=[\"departure_time\"])\n",
    "        df_different_times = pd.DataFrame(columns=df_times.columns)\n",
    "    else:\n",
    "        # only rows with arrival or departure times populated\n",
    "        df_times = df_trip_delay_data.dropna(how=\"all\", subset=[\"arrival_time\", \"departure_time\"])\n",
    "        # rows with different arrival and departure time (not including nans)\n",
    "        df_different_times = df_times[df_times[\"arrival_time\"] != df_times[\"departure_time\"]].dropna(how=\"any\", subset=[\"arrival_time\", \"departure_time\"])\n",
    "        # rows with only arrival or departure, but not both\n",
    "        df_either_times = df_times[df_times[[\"arrival_time\", \"departure_time\"]].isna().any(axis=1)]\n",
    "\n",
    "    # print statements about the data to try to see patterns\n",
    "    print(f\"{agency} - {len(df_trip_delay_data)} ({len(df_delays)}, {len(df_different_delays)}, {len(df_either_delays)}) ({len(df_times)}, {len(df_different_times)}, {len(df_either_times)})\")\n",
    "    if df_delays.empty and df_times.empty:\n",
    "        print(\"  no times or delays provided\")\n",
    "        continue\n",
    "    if df_delays.empty:\n",
    "        print(\"  delays not provided\")\n",
    "    else:\n",
    "        if not len(df_delays) == len(df_trip_delay_data):\n",
    "            pct = min(.999, len(df_delays)/len(df_trip_delay_data))\n",
    "            print(f\"  delays only {pct:.1%} populated\")\n",
    "        # disjoint\n",
    "        if len(df_delays) == len(df_either_delays):\n",
    "            if df_either_delays[\"departure_delay\"].count() == len(df_delays):\n",
    "                print(\"  only departure_delay used\")\n",
    "            elif df_either_delays[\"arrival_delay\"].count() == len(df_delays):\n",
    "                print(\"  only arrival_delay used\")\n",
    "            elif 0 < df_either_delays[\"departure_delay\"].count() < df_either_delays[\"arrival_delay\"].count():\n",
    "                print(\"  departure delay is provided if currently at stop\")\n",
    "        # fully overlapping\n",
    "        elif df_delays[\"departure_delay\"].count() == df_delays[\"arrival_delay\"].count():\n",
    "            if df_delays[\"departure_delay\"].equals(df_delays[\"arrival_delay\"]):\n",
    "                print(\"  departure and arrival delays all equal\")\n",
    "            else:\n",
    "                pct = min(.999, 1-(len(df_different_delays)/len(df_delays)))\n",
    "                print(f\"  departure and arrival delays completely overlap, but only {pct:.1%} equal\")\n",
    "        # partially overlapping\n",
    "        else:\n",
    "            print(\"  departure and arrival delays partially overlap\")\n",
    "    if df_times.empty:\n",
    "        print(\"  times not provided\")\n",
    "    else:\n",
    "        if len(df_times) < len(df_trip_delay_data):\n",
    "            pct = min(.999, len(df_times)/len(df_trip_delay_data))\n",
    "            print(f\"  times only {pct:.1%} populated\")\n",
    "        # disjoint\n",
    "        if len(df_times) == len(df_either_times):\n",
    "            if df_either_times[\"departure_time\"].count() == len(df_times):\n",
    "                print(\"  only departure_time used\")\n",
    "            elif df_either_times[\"arrival_time\"].count() == len(df_times):\n",
    "                print(\"  only arrival_time used\")\n",
    "            elif 0 < df_either_times[\"departure_time\"].count() < df_either_times[\"arrival_time\"].count():\n",
    "                print(\"  departure time is provided if currently at stop\")\n",
    "        # fully overlapping\n",
    "        elif df_times[\"departure_time\"].count() == df_times[\"arrival_time\"].count():\n",
    "            if df_times[\"departure_time\"].equals(df_times[\"arrival_time\"]):\n",
    "                print(\"  departure and arrival times all equal\")\n",
    "            else:\n",
    "                pct = min(.999, 1-(len(df_different_times)/len(df_times)))\n",
    "                print(f\"  departure and arrival times completely overlap, but only {pct:.1%} equal\")\n",
    "        # partially overlapping\n",
    "        else:\n",
    "            print(\"  departure and arrival times partially overlap\")\n",
    "    # if \"arrival_time\" in df_trip_delay_data:\n",
    "    df_trip_delay_data[\"arrival_time_diff\"] = df_trip_delay_data[\"arrival_time\"] - df_trip_delay_data[\"timestamp\"]\n",
    "    df_trip_delay_data[\"arrival_time_diff_min\"] = df_trip_delay_data[\"arrival_time\"] - df_trip_delay_data[\"timestamp\"].min()\n",
    "    df_trip_delay_data[\"arrival_time_diff_max\"] = df_trip_delay_data[\"arrival_time\"] - df_trip_delay_data[\"timestamp\"].max()\n",
    "    df_trip_delay_data[\"departure_time_diff\"] = df_trip_delay_data[\"departure_time\"] - df_trip_delay_data[\"timestamp\"]\n",
    "    df_trip_delay_data[\"departure_time_diff_min\"] = df_trip_delay_data[\"departure_time\"] - df_trip_delay_data[\"timestamp\"].min()\n",
    "    df_trip_delay_data[\"departure_time_diff_max\"] = df_trip_delay_data[\"departure_time\"] - df_trip_delay_data[\"timestamp\"].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the data, determine which agencies fully populate the gps data, save summary to markdown file\n",
    "md_file = csv_folder.joinpath(\"summary.md\")\n",
    "trip_level_md_lines = []\n",
    "some_populated_md_lines = []\n",
    "none_populated_md_lines = []\n",
    "\n",
    "for agency, df_trip_delay_data in df_agency_trip_delay_data.items():\n",
    "    agency_name = agency.title().replace(\"_\", \" \")\n",
    "    # get agency feed documentation link\n",
    "    with open(config_folder.joinpath(f\"{agency}.json\")) as fp:\n",
    "        data = json.load(fp)\n",
    "        documentation_url = data.get(\"developer_resources\")\n",
    "        location = data.get(\"location\")\n",
    "        location_url_md = f\"[{location}]({documentation_url})\"\n",
    "\n",
    "    md_lines = [f\"### {agency_name}\", location_url_md]\n",
    "\n",
    "    # get trip-level summary if trip.delay used\n",
    "    if df_trip_delay_data[\"delay\"].any():\n",
    "        df_trip_data = df_trip_delay_data.drop_duplicates(\n",
    "            subset=[\"trip_id\", \"timestamp\", \"delay\"]\n",
    "        )\n",
    "        total_trip_count = df_trip_delay_data[\"trip_id\"].nunique()\n",
    "        any_trip_delay_count = (\n",
    "            df_trip_data.groupby(\"trip_id\")[\"delay\"].any().sum()\n",
    "        )\n",
    "        mean_trip_delay_count_coverage = (\n",
    "            df_trip_data.groupby(\"trip_id\")[\"delay\"]\n",
    "            .apply(lambda x: x.notnull().mean())\n",
    "            .mean()\n",
    "        )\n",
    "        trip_coverage_summary = pd.DataFrame(\n",
    "            {\n",
    "                f\"trip_delay_counts, total={total_trip_count}\": [f\"{any_trip_delay_count}\"],\n",
    "                \"mean_trip_delay_coverage\": [f\"{mean_trip_delay_count_coverage:.1%}\"],\n",
    "                \"any_trip_delay_coverage\": [f\"{any_trip_delay_count/total_trip_count:.1%}\"],\n",
    "            },\n",
    "        )\n",
    "        md_lines += [\n",
    "            \"#### trip-level summary\",\n",
    "            trip_coverage_summary.to_markdown(index=False, disable_numparse=True),\n",
    "            \"\",\n",
    "            \"#### Sample of trip-level delay data\",\n",
    "            df_trip_data.sample(10).to_markdown(index=False),\n",
    "            \"\",\n",
    "        ]\n",
    "        trip_level_md_lines += md_lines\n",
    "        continue\n",
    "    # else\n",
    "    # get stop-level summary using each stop.delay\n",
    "    total_stop_count = len(df_trip_delay_data[[\"arrival_delay\", \"departure_delay\"]])\n",
    "    df_trip_delay_data[\"Either\"] = df_trip_delay_data[[\"arrival_delay\", \"departure_delay\"]].mean(axis=1)\n",
    "    stop_delay_keys = [\"arrival_delay\", \"departure_delay\", \"Either\"]\n",
    "    stop_delay_counts = df_trip_delay_data[stop_delay_keys].count()\n",
    "    stop_coverage_summary = pd.DataFrame(\n",
    "        {\n",
    "            f\"stop_delay_counts, total={total_stop_count}\": [f\"{x}\" for x in stop_delay_counts],\n",
    "            \"total_stop_delay_coverage\": [f\"{x/total_stop_count:.1%}\" for x in stop_delay_counts],\n",
    "        },\n",
    "        index=stop_delay_keys,\n",
    "    )\n",
    "\n",
    "    # get trip-level summary using stop.delay per trip\n",
    "    any_trip_stop_delay_counts = (\n",
    "        df_trip_delay_data.groupby(\"trip_id\")[stop_delay_keys]\n",
    "        .apply(lambda x: x.notnull().any())\n",
    "        .sum()\n",
    "    )\n",
    "    mean_trip_stop_delay_count_coverage = (\n",
    "            df_trip_delay_data.groupby(\"trip_id\")[stop_delay_keys]\n",
    "            .apply(lambda x: x.notnull().mean())\n",
    "            .mean()\n",
    "        )\n",
    "    total_trip_count = df_trip_delay_data[\"trip_id\"].nunique()\n",
    "    trip_coverage_summary = pd.DataFrame(\n",
    "        {\n",
    "            f\"any_trip_stop_delay_counts, total={total_trip_count}\": [f\"{x}\" for x in any_trip_stop_delay_counts],\n",
    "            \"mean_stop_delay_coverage_per_trip\": [f\"{x:.1%}\" for x in mean_trip_stop_delay_count_coverage],\n",
    "            \"any_trip_delay_coverage\": [f\"{x/total_trip_count:.1%}\" for x in any_trip_stop_delay_counts],\n",
    "        },\n",
    "        index=stop_delay_keys,\n",
    "    )\n",
    "    # print(partial_trip_summary.to_markdown(index = False, disable_numparse=True))\n",
    "\n",
    "    md_lines += [\n",
    "        \"#### stop-level summary\",\n",
    "        stop_coverage_summary.to_markdown(disable_numparse=True),\n",
    "        \"\",\n",
    "        \"#### stop-level summary per trip\",\n",
    "        trip_coverage_summary.to_markdown(disable_numparse=True),\n",
    "        \"\",\n",
    "        \"#### Sample of stop-level delay data\",\n",
    "        df_trip_delay_data.sample(10).to_markdown(index=False),\n",
    "        \"\",\n",
    "    ]\n",
    "\n",
    "    # split agencies into groups that provide all, some and no delay data\n",
    "    if any_trip_stop_delay_counts[\"Either\"] > 0:\n",
    "        some_populated_md_lines += md_lines\n",
    "    else:\n",
    "        none_populated_md_lines += md_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write each group to a markdown file\n",
    "with open(md_file, \"w\") as fp:\n",
    "    print(f\"## Agencies with Trip-Level trip_delay_data\", file=fp)\n",
    "    print(\n",
    "        \"This only seems to be used by MTA_NYC, though it does seem like the simplest\",\n",
    "        \"way to get provide current schedule adherence that is not as granular as\",\n",
    "        \"the predicted delay for each stop. Table includes first StopTimeUpdate.\",\n",
    "        sep=\" \",\n",
    "        file=fp\n",
    "    )\n",
    "    print(*trip_level_md_lines, sep=\"\\n\", file=fp)\n",
    "    print(f\"## Agencies with trip_delay_data partially provided in StopTimeUpdates\", file=fp)\n",
    "    print(*some_populated_md_lines, sep=\"\\n\", file=fp)\n",
    "    print(f\"## Agencies with trip_delay_data not directly provided\", file=fp)\n",
    "    print(*none_populated_md_lines, sep=\"\\n\", file=fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the execution here when selecting \"Run All\", while not closing the kernel,\n",
    "# still allowing the below cells to be run manually\n",
    "raise SystemExit(\"Done, the following cells can be executed manually\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "Alternatively, you could get the data from redis, with the api poller putting it there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsp_gtfs_realtime import AWSConfig\n",
    "from tsp_gtfs_realtime.vehicle_manager import VehicleSubscriber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create video subscriber and subscribe to all vehicle updates\n",
    "aws_cfg = AWSConfig(\n",
    "    local_development=True,\n",
    "    redis_url=\"localhost\",\n",
    "    redis_port=6379,\n",
    ")\n",
    "vehicle_subscriber = VehicleSubscriber(aws_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first message is the subscription notification\n",
    "msg = vehicle_subscriber.pubsub.get_message()\n",
    "\n",
    "# get new vehicle_position message and vehicle_id\n",
    "msg = vehicle_subscriber.pubsub.get_message()\n",
    "vehicle_id = msg[\"channel\"].split(\":\")[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new vehicle_position data from cache\n",
    "vehicle_subscriber.get_updated_vehicle_position(vehicle_id)\n",
    "\n",
    "# get fields for trip_delay_data AirLink Telemetry Protocol (ATP)\n",
    "trip_delay_data = GPSData(\n",
    "    vehicle_id=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"vehicle_id\"),\n",
    "    timestamp=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"timestamp\"),\n",
    "    latitude=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"latitude\"),\n",
    "    longitude=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"longitude\"),\n",
    "    bearing=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"bearing\"),\n",
    "    speed=vehicle_subscriber.vehicle_positions[vehicle_id].get(\"speed\"),\n",
    ")\n",
    "\n",
    "print(f\"{vehicle_id}: {trip_delay_data!r}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
